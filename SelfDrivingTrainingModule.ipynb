{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read driving_log in as pandas.dataframe\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "datapath = '/home/microway/Shuo/CarND/CarND-BehaviorCloning-Project/data-given/'\n",
    "data = pd.read_csv(datapath + 'driving_log.csv',delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "image=cv2.imread(datapath + data['center'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "# 1. Brightness augmentation\n",
    "def brightness_jitter(image):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    bright_jitter_rate = .25+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*bright_jitter_rate\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Horizontal and vertical shifts\n",
    "# We will shift the camera images horizontally to simulate the effect of car being at different positions on the road,\n",
    "# and add an offset corresponding to the shift to the steering angle. We added 0.004 steering angle units per pixel \n",
    "# shift to the right, and subtracted 0.004 steering angle units per pixel shift to the left. We will also shift the \n",
    "# images vertically by a random number to simulate the effect of driving up or down the slope.\n",
    "def steering_jitter(image,steer,trans_range):\n",
    "    # Translation\n",
    "    rows,cols,cha = image.shape  \n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    steer_ang = steer + tr_x/trans_range*2*.2\n",
    "    tr_y = 40*np.random.uniform()-40/2\n",
    "    #tr_y = 0\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "    image_tr = cv2.warpAffine(image,Trans_M,(cols,rows))\n",
    "    \n",
    "    return image_tr,steer_ang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Shadow augmentation\n",
    "# The next augmentation we will add is shadow augmentation where random shadows are cast across the image. \n",
    "# This is implemented by choosing random points and shading all points on one side (chosen randomly) of the image. \n",
    "# The code for this augmentation is presented below.\n",
    "def shadow_jitter(image):\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_size_col,new_size_row=64,64\n",
    "def preprocessImage(image):\n",
    "    shape = image.shape\n",
    "    # note: numpy arrays are (row, col)!\n",
    "    image = image[math.floor(shape[0]/5):shape[0]-25, 0:shape[1]]\n",
    "    image = cv2.resize(image,(new_size_col,new_size_row),interpolation=cv2.INTER_AREA)    \n",
    "    #image = image/255.-.5\n",
    "    return image\n",
    "def preprocess_image_file_train(line_data):\n",
    "    i_lrc = np.random.randint(3)\n",
    "    if (i_lrc == 0):\n",
    "        path_file = line_data['left'][0].strip()\n",
    "        shift_ang = .25\n",
    "    if (i_lrc == 1):\n",
    "        path_file = line_data['center'][0].strip()\n",
    "        shift_ang = 0.\n",
    "    if (i_lrc == 2):\n",
    "        path_file = line_data['right'][0].strip()\n",
    "        shift_ang = -.25\n",
    "    y_steer = line_data['steering'][0] + shift_ang\n",
    "    image = cv2.imread(datapath+path_file)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image,y_steer = steering_jitter(image,y_steer,100)\n",
    "    image = brightness_jitter(image)\n",
    "    image = preprocessImage(image)\n",
    "    image = np.array(image)\n",
    "    ind_flip = np.random.randint(2)\n",
    "    if ind_flip==0:\n",
    "        image = cv2.flip(image,1)\n",
    "        y_steer = -y_steer\n",
    "    \n",
    "    return image,y_steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will utilize keraâ€™s generator function to sample images such that images with \n",
    "# lower angles have lower probability of getting represented in the data set.\n",
    "def generate_train_from_PD_batch(data,batch_size = 32):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, new_size_row, new_size_col, 3))\n",
    "    batch_steering = np.zeros(batch_size)\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            i_line = np.random.randint(len(data))\n",
    "            line_data = data.iloc[[i_line]].reset_index()\n",
    "            \n",
    "            keep_pr = 0\n",
    "            #x,y = preprocess_image_file_train(line_data)\n",
    "            while keep_pr == 0:\n",
    "                x,y = preprocess_image_file_train(line_data)\n",
    "                pr_unif = np.random\n",
    "                if abs(y)<.1:\n",
    "                    pr_val = np.random.uniform()\n",
    "                    if pr_val>pr_threshold:\n",
    "                        keep_pr = 1\n",
    "                else:\n",
    "                    keep_pr = 1\n",
    "            \n",
    "            #x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "            #y = np.array([[y]])\n",
    "            batch_images[i_batch] = x\n",
    "            batch_steering[i_batch] = y\n",
    "        yield batch_images, batch_steering\n",
    "    return batch_images, batch_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# construct model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Flatten, Input, Dropout, MaxPooling2D, Activation\n",
    "from keras.models import model_from_json\n",
    "from keras.activations import relu, softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3,input_shape=(64, 64, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "# Compile model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 79s - loss: 369958.7628 - mean_squared_error: 369958.7629    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/microway/anaconda3/envs/TensorFlowGPU/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 78s - loss: 20.1209 - mean_squared_error: 20.1209    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 78s - loss: 1.6215 - mean_squared_error: 1.6215    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 79s - loss: 1.2980 - mean_squared_error: 1.2980    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 78s - loss: 1.1190 - mean_squared_error: 1.1190    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 79s - loss: 1.0335 - mean_squared_error: 1.0335    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 79s - loss: 0.9229 - mean_squared_error: 0.9229    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.8188 - mean_squared_error: 0.8188    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.7819 - mean_squared_error: 0.7819    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.7165 - mean_squared_error: 0.7165    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.6573 - mean_squared_error: 0.6573    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.6027 - mean_squared_error: 0.6027    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.5827 - mean_squared_error: 0.5827    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.5245 - mean_squared_error: 0.5245    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.5122 - mean_squared_error: 0.5122    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.4842 - mean_squared_error: 0.4842    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.4719 - mean_squared_error: 0.4719    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.4463 - mean_squared_error: 0.4463    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.4261 - mean_squared_error: 0.4261    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 78s - loss: 0.4302 - mean_squared_error: 0.4302    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 74s - loss: 0.3932 - mean_squared_error: 0.3932    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.3683 - mean_squared_error: 0.3683    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.3545 - mean_squared_error: 0.3545    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.3355 - mean_squared_error: 0.3355    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 68s - loss: 0.3263 - mean_squared_error: 0.3263    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.3298 - mean_squared_error: 0.3298    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 68s - loss: 0.3507 - mean_squared_error: 0.3507    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.2843 - mean_squared_error: 0.2843    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.2845 - mean_squared_error: 0.2845    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 69s - loss: 0.2661 - mean_squared_error: 0.2661    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2692 - mean_squared_error: 0.2692    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2486 - mean_squared_error: 0.2486    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2478 - mean_squared_error: 0.2478    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2360 - mean_squared_error: 0.2360    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 67s - loss: 0.2323 - mean_squared_error: 0.2323    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2463 - mean_squared_error: 0.2463    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2394 - mean_squared_error: 0.2394    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2189 - mean_squared_error: 0.2189    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 67s - loss: 0.2315 - mean_squared_error: 0.2315    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2362 - mean_squared_error: 0.2362    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 65s - loss: 0.2529 - mean_squared_error: 0.2529    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 65s - loss: 0.2687 - mean_squared_error: 0.2687    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2636 - mean_squared_error: 0.2636    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.2390 - mean_squared_error: 0.2390    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 65s - loss: 0.2962 - mean_squared_error: 0.2962    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 65s - loss: 0.3471 - mean_squared_error: 0.3471    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 66s - loss: 0.3097 - mean_squared_error: 0.3097    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 65s - loss: 0.5918 - mean_squared_error: 0.5918    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 66s - loss: 8.0914 - mean_squared_error: 8.0914    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 65s - loss: 32.6788 - mean_squared_error: 32.6788    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 65s - loss: 1.6790 - mean_squared_error: 1.6790    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 64s - loss: 1.0504 - mean_squared_error: 1.0504    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.5972 - mean_squared_error: 0.5972    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 64s - loss: 20.1124 - mean_squared_error: 20.1124    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 64s - loss: 2.0155 - mean_squared_error: 2.0155    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 64s - loss: 3.2553 - mean_squared_error: 3.2553    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 65s - loss: 7.2202 - mean_squared_error: 7.2202    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 65s - loss: 70.3633 - mean_squared_error: 70.3633    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 64s - loss: 1.0077 - mean_squared_error: 1.0077    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.7076 - mean_squared_error: 0.7076    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.5210 - mean_squared_error: 0.5210    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.7321 - mean_squared_error: 0.7321    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.4902 - mean_squared_error: 0.4902    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.9167 - mean_squared_error: 0.9167    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 64s - loss: 1.6739 - mean_squared_error: 1.6739    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 65s - loss: 6.8210 - mean_squared_error: 6.8210    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 65s - loss: 44.1730 - mean_squared_error: 44.1730    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 65s - loss: 1.9063 - mean_squared_error: 1.9063    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.6251 - mean_squared_error: 0.6251    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.3949 - mean_squared_error: 0.3949    \n",
      "Epoch 1/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.4671 - mean_squared_error: 0.4671    \n",
      "Epoch 2/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.9669 - mean_squared_error: 0.9669    \n",
      "Epoch 3/10\n",
      "20224/20000 [==============================] - 64s - loss: 42.0618 - mean_squared_error: 42.0618    \n",
      "Epoch 4/10\n",
      "20224/20000 [==============================] - 64s - loss: 6.3791 - mean_squared_error: 6.3791    \n",
      "Epoch 5/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.6931 - mean_squared_error: 0.6931    \n",
      "Epoch 6/10\n",
      "20224/20000 [==============================] - 63s - loss: 0.4088 - mean_squared_error: 0.4088    \n",
      "Epoch 7/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.4333 - mean_squared_error: 0.4333    \n",
      "Epoch 8/10\n",
      "20224/20000 [==============================] - 64s - loss: 0.4722 - mean_squared_error: 0.4722    \n",
      "Epoch 9/10\n",
      "20224/20000 [==============================] - 63s - loss: 0.4641 - mean_squared_error: 0.4641    \n",
      "Epoch 10/10\n",
      "20224/20000 [==============================] - 64s - loss: 2.0332 - mean_squared_error: 2.0332    \n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "# data is pandaâ€™s dataframe that has path to the image files and steering data\n",
    "import numpy as np\n",
    "\n",
    "val_size = 1 \n",
    "pr_threshold = 1\n",
    "batch_size = 256\n",
    "for i_pr in range(8):\n",
    "    train_r_generator = generate_train_from_PD_batch(data,batch_size)\n",
    "    \n",
    "    nb_vals = np.round(len(data)/val_size)-1\n",
    "    model.fit_generator(train_r_generator,samples_per_epoch=20000, nb_epoch=1,verbose=1)\n",
    "    pr_threshold = 1/(i_pr+1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "loaded_model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras save and reuse model: http://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# MLP for Pima Indians Dataset serialize to JSON and HDF5\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "model.add(Dense(8, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# later...\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print \"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Steering angle prediction model\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "\n",
    "from server import client_generator\n",
    "\n",
    "\n",
    "def gen(hwm, host, port):\n",
    "  for tup in client_generator(hwm=hwm, host=host, port=port):\n",
    "    X, Y, _ = tup\n",
    "    Y = Y[:, -1]\n",
    "    if X.shape[1] == 1:  # no temporal context\n",
    "      X = X[:, -1]\n",
    "    yield X, Y\n",
    "\n",
    "\n",
    "def get_model(time_len=1):\n",
    "  ch, row, col = 3, 160, 320  # camera format\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "            input_shape=(ch, row, col),\n",
    "            output_shape=(ch, row, col)))\n",
    "  model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "  model.add(ELU())\n",
    "  model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "  model.add(ELU())\n",
    "  model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dropout(.2))\n",
    "  model.add(ELU())\n",
    "  model.add(Dense(512))\n",
    "  model.add(Dropout(.5))\n",
    "  model.add(ELU())\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser(description='Steering angle model trainer')\n",
    "  parser.add_argument('--host', type=str, default=\"localhost\", help='Data server ip address.')\n",
    "  parser.add_argument('--port', type=int, default=5557, help='Port of server.')\n",
    "  parser.add_argument('--val_port', type=int, default=5556, help='Port of server for validation dataset.')\n",
    "  parser.add_argument('--batch', type=int, default=64, help='Batch size.')\n",
    "  parser.add_argument('--epoch', type=int, default=200, help='Number of epochs.')\n",
    "  parser.add_argument('--epochsize', type=int, default=10000, help='How many frames per epoch.')\n",
    "  parser.add_argument('--skipvalidate', dest='skipvalidate', action='store_true', help='Multiple path output.')\n",
    "  parser.set_defaults(skipvalidate=False)\n",
    "  parser.set_defaults(loadweights=False)\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  model = get_model()\n",
    "  model.fit_generator(\n",
    "    gen(20, args.host, port=args.port),\n",
    "    samples_per_epoch=10000,\n",
    "    nb_epoch=args.epoch,\n",
    "    validation_data=gen(20, args.host, port=args.val_port),\n",
    "    nb_val_samples=1000\n",
    "  )\n",
    "  print(\"Saving model weights and configuration file.\")\n",
    "\n",
    "  if not os.path.exists(\"./outputs/steering_model\"):\n",
    "      os.makedirs(\"./outputs/steering_model\")\n",
    "\n",
    "  model.save_weights(\"./outputs/steering_model/steering_angle.keras\", True)\n",
    "  with open('./outputs/steering_model/steering_angle.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlowGPU]",
   "language": "python",
   "name": "conda-env-TensorFlowGPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
